{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nearest Means Classifier\n",
    "This sheet shows how to use the helper function `plotDecBoundaries` that is provided for homework assignment 1.  This allows you to visualize the decision boundaries with a nearest mean classifier.  \n",
    "\n",
    "First, let's import the the helper function from the `utils` directory.  Note that this assumes that the file `plotDecBoundaries.py` is in the directory `utils` which is a subdirectory in the directory containing this file.  Another approach is to put the `utils` directory someplace else on your hard-drive and include the parent directory in your `PYTHONPATH`.  The advantage of this second approach is that you can use the `utils` directory in many different projects that are not all in the same directory without duplicating the `utils` drdirectoryctory.  For more information: [setting your Python path](https://www.techwalla.com/articles/how-to-set-your-python-path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plotDecBoundaries import plotDecBoundaries\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some data to pass to the `plotDecBoundaries` helper function.  We need to generate data from 2 classes.  Let's generate data from a Gaussian distribution with a given mean vectore and variance.  This assumes the $x$ and $y$ coordinates are independent and have the same variance.  The  `plotDecBoundaries` helper function expects to see this data passed as a single array of 2D points with an associated labels array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 =  np.asarray([5, 5])\n",
    "sigma1 = 2\n",
    "\n",
    "m2 = np.asarray([5, -5])\n",
    "sigma2 = 2\n",
    "\n",
    "N1 = 200\n",
    "N2 = 200\n",
    "N = N1 + N2\n",
    "\n",
    "x = np.zeros((N, 2))\n",
    "x[:N1] = np.random.normal(0, sigma1, (N1, 2)) + m1\n",
    "x[N1:] = np.random.normal(0, sigma2, (N2, 2)) + m2\n",
    "\n",
    "labels = np.ones(N)\n",
    "labels[N1:] += 1\n",
    "\n",
    "sample_means = np.zeros((2,2))\n",
    "sample_means[0] = np.mean(x[:N1], axis=0)\n",
    "sample_means[1] = np.mean(x[N1:], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check to see what the sample means are compared to the means (ensemble average):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{N} total data points.  {N1} in class 1 and {N2} in class 2\\n')\n",
    "\n",
    "print(f'The mean in the generating pdf for class 1 is: {m1}')\n",
    "print(f'The sample mean for class 1 data is: {sample_means[0]}\\n')\n",
    "\n",
    "print(f'The mean in the generating pdf for class 2 is: {m2}')\n",
    "print(f'The sample mean for class 2 data is: {sample_means[1]}')\n",
    "\n",
    "np.mean(x[N1:] ).shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the helper function provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDecBoundaries(x, labels, sample_means, fsize=(18,18))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function to make the data generation a little more compact:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_white_gaussian_data(means, sigmas, Ns):\n",
    "    N = Ns[0] + Ns[1]\n",
    "    x = np.zeros((N, 2))\n",
    "    x[:Ns[0]] = np.random.normal(0, sigmas[0], (Ns[0], 2)) + means[0]\n",
    "    x[Ns[0]:] = np.random.normal(0, sigmas[1], (Ns[1], 2)) + means[1]\n",
    "\n",
    "    labels = np.ones(Ns[0] + Ns[1])\n",
    "    labels[Ns[0]:] += 1\n",
    "\n",
    "    sample_means = np.zeros((2,2))\n",
    "    sample_means[0] = np.mean(x[:Ns[0]], axis=0)\n",
    "    sample_means[1] = np.mean(x[Ns[0]:], axis=0)\n",
    "\n",
    "    return x, labels, sample_means"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's use this function to repeat the above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.asarray([ [5,5], [5, -5]])\n",
    "sigmas = np.asarray([2,2])\n",
    "Ns = np.asarray([20,200])\n",
    "\n",
    "x, labels, sample_means = generate_white_gaussian_data(means, sigmas, Ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotDecBoundaries(x, labels, sample_means, fsize=(18,18))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More complex examples\n",
    "\n",
    "The nearest means classifier makes reasonable intuitive sense.  How can we generate some data that will cause problems for this classifier?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6200758b7673adf34ae50bfa4217006f2c557feffe45080c236eaee64db53788"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
